# -*- coding: utf-8 -*-
"""Assignment1DataMining.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uDJURlH2APBCMU1yACX82484R2NlLGju
"""

import pandas as pd
from itertools import combinations
from collections import Counter
import itertools
from itertools import combinations
# Load the Excel file into a pandas dataframe
data = pd.read_excel('/content/CoffeeShopTransactions.xlsx')
data = data.replace('Caramel bites', 'CaramelBites')
# Display the dataframe
print(data)
# Get the list of unique items in the dataset
items = list(set(data.iloc[:, 3:].values.flatten()))
print(f"Items: {items}\n")

# Get user input for minimum support and minimum confidence
min_support = int(input("Enter the minimum support (from 0 to 6327): "))
min_confidence = int(input("Enter the minimum confidence (from 1% to 100%): "))
# Define a function to get the support count of all items
def get_item_support(data, items):
    # Initialize a dictionary to store the support count of each item
    support_counts = {}
    # Iterate through each item
    for item in items:
        # Count the number of transactions that contain the item
        count = sum(data.iloc[:, 3:].apply(lambda row: item in row.values, axis=1))
        # Add the support count to the dictionary
        support_counts[item] = count
    return support_counts
# Define a function to generate the candidate itemsets
def get_candidate_itemsets(data, items, k, min_support):
    # Generate all combinations of k items
    item_combinations = combinations(items, k)
    # Initialize a dictionary to store the support count of each combination
    support_counts = {}
    # Iterate through each combination
    for combination in item_combinations:
        # Count the number of transactions that contain all items in the combination
        count = sum(data.iloc[:, 3:].apply(lambda row: all(item in row.values for item in combination), axis=1))
        # If the support count is above the minimum support threshold, add the combination to the dictionary
        if count >= min_support:
            support_counts[combination] = count
            print(f"{combination}: {count}")
    return support_counts
  # Initialize the candidate itemsets
candidate_itemsets = {}

# Initialize an empty list to store the last candidate itemsets
last_itemsets = []

# Generate the candidate itemsets for k = 1
candidate_itemsets[1] = get_item_support(data, items)

# Iterate through each value of k until there are no more candidate itemsets
k = 2
while candidate_itemsets.get(k-1):
    # Generate the candidate itemsets for the current value of k
    candidate_itemsets[k] = get_candidate_itemsets(data, items, k, min_support)
    # If there are no candidate itemsets for the current value of k, break out of the loop
    if not candidate_itemsets[k]:
        break
    # If it is the last candidate itemset, add it to the last_itemsets list
    if not candidate_itemsets.get(k+1):
        last_itemsets = candidate_itemsets[k]
    # Print the candidate itemsets for the current value of k
    print(f"Candidate itemsets of size {k}: {candidate_itemsets[k]}")
    k += 1

print(last_itemsets) #frequent item sets

transactions = data.iloc[:, 3:].values
#print(transactions)
itemsets = []
for itemset in last_itemsets.keys():
    for i in range(1, len(itemset)+1):
        comb = combinations(itemset, i)
        for c in comb:
            if c not in itemsets:
                itemsets.append(c)
print(itemsets)
# Create a dictionary to store the support of each itemset
itemset_supports = {}
num_transactions = len(transactions)
for itemset in itemsets:
    count = 0
    for transaction in transactions:
        if set(itemset).issubset(set(transaction)):
            count += 1
    support = count / num_transactions
    itemset_supports[itemset] = support

# Create a dictionary to store the confidence and lift of each rule
rule_confidences = {}
for itemset in itemset_supports:
    if len(itemset) > 1:
        for item in itemset:
            antecedent = tuple(sorted(filter(lambda x: x != item, itemset)))
            consequent = (item,)
            inantecedent = tuple(sorted(filter(lambda x: x != item, itemset)))
            inconsequent = (item,)
            if antecedent in itemset_supports:
                if itemset_supports[antecedent] == 0:
                    continue
                rule_confidence = itemset_supports[itemset] / itemset_supports[antecedent]
                confidence_percent = rule_confidence * 100
                inrule_confidence = itemset_supports[itemset] / itemset_supports[inconsequent]
                inconfidence_percent = inrule_confidence * 100
                lift=(itemset_supports[itemset]*len(transactions)) / (itemset_supports[consequent]*itemset_supports[antecedent])
                All_confidence=itemset_supports[itemset] / max(itemset_supports[consequent],itemset_supports[antecedent])
                max_confidence=itemset_supports[itemset] / min(itemset_supports[consequent],itemset_supports[antecedent])
                cos=itemset_supports[itemset]/((itemset_supports[consequent]*itemset_supports[antecedent])**(1/2))
                kulc=(All_confidence+max_confidence)/2
                inlift=(itemset_supports[itemset]*len(transactions)) / (itemset_supports[inconsequent]*itemset_supports[inantecedent])
                inAll_confidence=itemset_supports[itemset] / max(itemset_supports[inconsequent],itemset_supports[inantecedent])
                inmax_confidence=itemset_supports[itemset] / min(itemset_supports[inconsequent],itemset_supports[inantecedent])
                incos=itemset_supports[itemset]/((itemset_supports[inconsequent]*itemset_supports[inantecedent])**(1/2))
                inkulc=(inAll_confidence+inmax_confidence)/2
                if confidence_percent >= (min_confidence):
                    #print(confidence_percent)
                    #print(min_confidence)
                    print(f"Rule: {antecedent} => {consequent} | Confidence: {confidence_percent:.2f}%, lift: {lift:.2f}, All confidence: {All_confidence:.2f}, max confidence: {max_confidence:.2f}, kulc: {kulc:.2f}, cos: {cos:.2f}  ")
                    if(len(inantecedent)!=1): print(f"Rule: {inconsequent} => {inantecedent} | Confidence: {inconfidence_percent:.2f}%, lift: {lift:.2f}, All confidence: {inAll_confidence:.2f}, max confidence: {inmax_confidence:.2f}, kulc: {inkulc:.2f}, cos: {incos:.2f}  ")
                    print("This rule is above the minimum confidence threshold")
                #else:
                    #print(f"Rule: {antecedent} => {consequent} | Confidence: {confidence_percent:.2f}%, lift: {lift:.2f}, All confidence: {All_confidence:.2f}, max confidence: {max_confidence:.2f}, kulc: {kulc:.2f}, cos: {cos:.2f}  ")
                    #if(len(inantecedent)!=1): print(f"Rule: {inconsequent} => {inantecedent} | Confidence: {inconfidence_percent:.2f}%, lift: {lift:.2f}, All confidence: {inAll_confidence:.2f}, max confidence: {inmax_confidence:.2f}, kulc: {inkulc:.2f}, cos: {incos:.2f}  ")
                    #print("This rule is below the minimum confidence threshold")